-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
current project tree
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------

lane-detection
│   .gitignore
│   LICENSE
│   README.md
│
├── data
│   ├── frames_sample/
│   │       frame_t1_f60.png
│   │       frame_t4_f240.png
│   │       ...
│   │       frame_t295_f17700.png
│   │
│   ├── processed/
│   │       highway_clip.mp4
│   │
│   └── raw/
│           .gitkeep
│
├── notebooks/
│       01_explore_frames.ipynb
│       02_roi_exploration.ipynb
│       03_color_thresholding.ipynb
│       04_canny_edge_detection.ipynb
│
├── output/
│   ├── final_videos/
│   │       .gitkeep
│   │
│   └── logs/
│       │   algorithm_log.txt
│       │
│       └── debug_frames/
│               .gitkeep
│
├── report/
│       .gitkeep
│
└── src/
    │   lane_detection.py
    │   pipeline.py
    │   pre_processing.py
    │
    ├── enhancements/
    │       .gitkeep
    │
    └── utils/
            debug.py
            drawing.py
            geometry.py
            image_ops.py
            video.py
            __init__.py

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
stage 1 - Pre-processing Stage – Frames Extraction
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Pre-processing Stage – Frames Extraction

Status: Completed successfully
Description:
Extracted representative frames from the main video (highway_clip.mp4) for exploratory analysis and algorithm development.
Two extraction strategies were used:

Uniform sampling — saved every 50 frames into data/frames/ to obtain general road scenarios.

Targeted extraction — saved 36 manually selected timestamps into data/frames_sample/ representing:

straight-lane conditions

strong shadows

bright lighting

lane boundaries variability

lane change events

traffic interaction scenarios

These frames will be used throughout development to tune ROI, Canny thresholds, line detection, and lane-change logic.

Next steps:
Start exploring the selected frames in a dedicated notebook (01_explore_frames.ipynb) and identify stable patterns in lane geometry, colors, and noise sources.


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Stage 2 — Frame Exploration & Pattern Identification
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Stage 2 — Frame Exploration & Pattern Identification

Status: Completed successfully
Description:
Loaded and visualized the 36 curated sample frames inside the notebook (01_explore_frames.ipynb).
The goal of this stage is to understand the visual variability in the dataset and identify parameters that must be robust across all scenarios.

The frame exploration focused on:

Differences in lighting 

Road curvature and perspective distortion

Variability in lane-marker width, color (white/yellow), and visibility

Occlusions from nearby vehicles

Frames where the host vehicle performs a lane change

Frames where other vehicles merge or cross lanes

These observations will guide the selection of:

ROI (Region of Interest) shape

Color threshold ranges for lane markings

Canny thresholds

Hough parameter ranges

Smoothing/temporal filtering strategy

Lane-change detection logic

Key accomplishments:

Created notebook 01_explore_frames.ipynb with organized frame categorization

Defined 4 frame categories for targeted testing:
ROI_FRAME_NAMES (8 frames) — for ROI mask tuning
CANNY_FRAME_NAMES (8 frames) — for edge detection parameter tuning
HOUGH_FRAME_NAMES (8 frames) — for line detection validation
LANE_CHANGE_FRAME_NAMES (10 frames) — for lane-change event detection

Identified visual challenges:
Shadow interference on white lane markings
Bright reflections and glare
Curved road sections with perspective distortion
Adjacent vehicles partially occluding lane boundaries
Yellow and white lane transitions

These categorized frames serve as test sets for each pipeline stage, ensuring algorithm robustness.

Next steps:
Define ROI geometry and test it across representative frames (02_roi_exploration.ipynb).

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Stage 2.5 — ROI (Region of Interest) Exploration
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Stage 2.5 — ROI (Region of Interest) Exploration

Status: Completed successfully
Description:
Defined and tuned a trapezoidal Region of Interest (ROI) mask to focus the lane detection algorithm on the relevant road area.
The goal of this stage was to exclude irrelevant image regions (sky, roadside, distant lanes) and concentrate computational resources on the immediate driving lane.

The ROI exploration focused on:

Testing different trapezoid shapes across various road perspectives

Finding optimal vertical cutoff (how much road ahead to include)

Balancing between capturing curved lanes and excluding irrelevant regions

Validating ROI stability across straight roads, curves, and lane changes

The trapezoid shape was chosen because it mimics natural perspective: lanes appear wide near the camera and converge toward the horizon.
This geometric constraint matches road physics and reduces false positives from non-road features.

The finalized ROI parameters successfully isolate the driving lane across all test scenarios, creating a focused region for subsequent color and edge detection stages.

Next steps:
Apply color thresholding within the ROI to isolate white and yellow lane markings.


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Stage 3 — Color Thresholding
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Stage 3 — Color Thresholding

Status: Completed successfully
Description:
Implemented HSV-based color segmentation to isolate white and yellow lane markings from the road scene.
This stage focused on finding robust threshold values that work across varying lighting conditions (shadows, bright sun, tunnels).

The color thresholding exploration focused on:

Converting ROI-masked frames from BGR to HSV color space for more intuitive color-based segmentation

Identifying HSV ranges that reliably capture white lane markings (high brightness, low saturation)

Identifying HSV ranges that reliably capture yellow lane markings (hue around 20-30 degrees)

Testing threshold stability across shadows, bright reflections, and varying road textures

Combining white and yellow detections to create unified lane masks

Applying morphological operations to remove small noise and fill gaps in detected lanes

The HSV color space was chosen because it separates brightness (Value) from color information (Hue, Saturation),
making it more robust to lighting variations than RGB/BGR. White lanes are characterized by high brightness and low color saturation,
while yellow lanes have a distinct hue around 20-30 degrees.

The finalized thresholds successfully produce clean binary masks where lane markings appear as white (255) and background as black (0).
These binary masks eliminate most road texture, shadows, and non-lane features, creating a focused input for edge detection.

Validation was performed across 16 diverse test frames representing different lighting conditions, road curvatures, and traffic scenarios.

Next steps:
Apply Canny edge detection to the color-thresholded masks to extract precise edge contours for line detection.


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Stage 4 — Canny Edge Detection
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Stage 4 — Canny Edge Detection

Status: Completed successfully
Description:
Applied Canny edge detection to the color-thresholded lane masks to extract precise edge boundaries.
This stage focused on finding optimal Canny threshold parameters that produce clean, continuous edges while suppressing noise.

The Canny edge detection exploration focused on:

Applying Gaussian blur preprocessing to reduce high-frequency noise before edge detection

Testing multiple threshold pairs to find the optimal balance:
Low thresholds (30/90) — too sensitive, captures noise and texture
Medium thresholds (50/150) — optimal, captures strong and moderate edges
High thresholds (70/210, 100/200) — too conservative, misses valid lane edges

Validating edge continuity across straight lanes, curves, and lane-change scenarios

Ensuring edge detection works consistently across varying lighting conditions (shadows, reflections, tunnels)

Canny edge detection uses hysteresis thresholding with two threshold values:
High threshold identifies strong edges (definite lane boundaries)
Low threshold extends edges from strong points, capturing weaker but connected edge segments

The Gaussian blur step is critical because Canny is sensitive to noise. By smoothing the image first,
we suppress texture noise while preserving true lane edge structures.

The finalized parameters (low=50, high=150, blur_kernel=5) successfully produce binary edge maps with well-defined, continuous lane boundaries.
These edges eliminate the interior regions of lane markings and focus only on the boundary contours,
which is essential for accurate line fitting in the next stage.

Validation was performed across all 16 test frames, confirming robust edge extraction in diverse scenarios.

Next steps:
Apply Hough line detection to the edge maps to identify candidate line segments, then fit polynomial curves to represent lane boundaries.


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Stage 5
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
